\chapter{Minimax}

\section{Definition der Umgebung}

Betrachten wir ein Nullsummenspiel mit zwei Akteuren $P = \{\text{\scshape
Max}, \text{\scshape Min}\}$, deren Ziele einander widersprechen.

Jedem Spielzustand $s \in S$ entspricht ein Spielwert $\text{\scshape eval}(s)
\in [-1,1]$. Dabei erhalten terminale Zustände den Wert

\begin{itemize}
    \item $\text{\scshape eval}(s) = 1$, wenn \textsc{Max} gewinnt,
    \item $\text{\scshape eval}(s) = -1$, wenn \textsc{Min} gewinnt,
    \item oder $\textsc{\scshape eval}(s) = 0$ bei einem Unentschieden.
\end{itemize}

Für nicht-terminale Zustände liegt der Wert im offenen Intervall $(-1,1)$,
wobei positive Werte \textsc{Max} und negative Werte \textsc{Min} begünstigen.

\section{Optimale Entscheidungsfindung}

Aus einem gegebenen Spielbaum lässt sich eine optimale Strategie ableiten,
indem die sogenannten \textbf{Minimax-Werte} der Knoten berechnet werden.

Blattknoten, die entweder terminale Zustände oder die Endpunkte eines auf eine
bestimmte Tiefe begrenzten Spielbaums darstellen, übernehmen dabei einfach den
Spielwert, den $\text{\scshape eval}(s)$ liefert. In nicht-terminalen Zuständen
wählt \textsc{Max} den größten und \textsc{Min} den kleinsten Wert unter den
Nachfolgern, wodurch die Werte der Blattknoten bis zur Wurzel des Baums
zurückpropagiert werden. Formal lässt sich dies wie folgt ausdrücken:
\begin{equation}
    \text{\textsc{minimax}(s)} =
    \begin{cases}
        \text{\textsc{eval}}(s) & \text{falls} \; s \; \text{ein Blattknoten ist}, \\
        \text{max}_{s' \in A(s)} \text{\textsc{minimax}}(s') & \text{falls \textsc{to-move}}(s) = \text{\textsc{Max}}, \\
        \text{min}_{s' \in A(s)} \text{\textsc{minimax}}(s') & \text{falls \textsc{to-move}}(s) = \text{\textsc{Min}}.
    \end{cases}
    \label{eq:minimax}
\end{equation}

Der beste Zug ist stets derjenige Nachfolger, der für den Spieler den optimalen
Minimax-Wert liefert.

\begin{figure}[h]
    \centering

    \begin{subfigure}[t]{0.49\textwidth}
        \includegraphics[width=\linewidth]{Abbildungen/minimax-a.png}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.49\textwidth}
        \includegraphics[width=\linewidth]{Abbildungen/minimax-b.png}
    \end{subfigure}

    \begin{subfigure}[t]{0.49\textwidth}
        \includegraphics[width=\linewidth]{Abbildungen/minimax-c.png}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.49\textwidth}
        \includegraphics[width=\linewidth]{Abbildungen/minimax-d.png}
    \end{subfigure}

    \begin{subfigure}[t]{0.49\textwidth}
        \includegraphics[width=\linewidth]{Abbildungen/minimax-e.png}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.49\textwidth}
        \includegraphics[width=\linewidth]{Abbildungen/minimax-f.png}
    \end{subfigure}

    \caption{Minimax-Algorithmus auf einem 2-Ply-Spielbaum}
    \label{fig:minimax-on-a-2-ply-game-tree}
\end{figure}

Die Abbildung oben illustriert anschaulich den Minimax-Algorithmus auf einem
2-Ply-Spielbaum mit dem \textsc{Max}-Knoten an der Wurzel. Die optimalste
Zugfolge verläuft dabei über die Knoten $\text{D} \rightarrow \text{A}
\rightarrow 0,7$.

\section{Spielbaum-Pruning}

Die Berechnung der Minimax-Werte erfordert im Worst-Case die vollständige
Auswertung des Spielbaums bis zur gewählten Suchtiefe.

\textbf{Alpha-Beta-Pruning} ist eine Optimierung des Minimax-Verfahrens, bei
der Teile des Spielbaums verworfen werden, wenn bereits feststeht, dass sie
keinen Einfluss auf die endgültige Entscheidung haben können. Das
Optimierungsverfahren hat ihren Namen von den beiden Parametern, die es
einführt:

\begin{itemize}
    \item Der Wert $\alpha$ der besten Entscheidung, die wir bisher an jedem
        Entscheidungspunkt entlang des Pfades für \textsc{Max} gefunden haben
    \item Der Wert $\beta$ der besten Entscheidung, die wir bisher an jedem
        Entscheidungspunkt entlang des Pfades für \textsc{Min} gefunden haben
\end{itemize}

Die Werte von $\alpha$ und $\beta$ werden während der Baumdurchsuchung
aktualisiert, wobei die verbleibenden Zweige abgeschnitten werden, sobald der
Wert am aktuellen Knoten für \textsc{Max} bzw. \textsc{Min} schlechter ist als
der jeweils aktuelle $\alpha$ bzw. $\beta$-Wert.

Die Abbildung~\ref{fig:alpha-beta-on-a-2-ply-game-tree} veranschaulicht die
Vorgehensweise anhand eines Spielbaums aus dem vorherigen Abschnitt. In diesem
Beispiel handelte es sich lediglich um Blattknoten, normalerweise werden jedoch
ganze Teilbäume abgeschnitten.

\begin{figure}[h]
    \centering

    \begin{subfigure}[t]{0.49\textwidth}
        \includegraphics[width=\linewidth]{Abbildungen/alpha-beta-a.png}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.49\textwidth}
        \includegraphics[width=\linewidth]{Abbildungen/alpha-beta-b.png}
    \end{subfigure}

    \begin{subfigure}[t]{0.49\textwidth}
        \includegraphics[width=\linewidth]{Abbildungen/alpha-beta-c.png}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.49\textwidth}
        \includegraphics[width=\linewidth]{Abbildungen/alpha-beta-d.png}
    \end{subfigure}

    \begin{subfigure}[t]{0.49\textwidth}
        \includegraphics[width=\linewidth]{Abbildungen/alpha-beta-e.png}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.49\textwidth}
        \includegraphics[width=\linewidth]{Abbildungen/alpha-beta-f.png}
    \end{subfigure}

    \caption{Alpha-Beta-Pruning auf einem 2-Ply-Spielbaum}
    \label{fig:alpha-beta-on-a-2-ply-game-tree}
\end{figure}

Eine weitere Form des Prunings im Spielbaum ist das sogenannte \textbf{Forward
Pruning}. Dabei werden Züge, die auf den ersten Blick wenig erfolgversprechend
erscheinen, vorzeitig abgeschnitten, um Rechenzeit zu sparen. Dies geschieht
jedoch auf Kosten der Genauigkeit, da dadurch potenziell gute Züge übersehen
werden können.

Ein spezieller Ansatz des Forward Prunings ist die \textbf{Late Move
Reduction}. Dabei wird angenommen, dass die Züge in sinnvoller Reihenfolge
untersucht werden, sodass die später betrachteten Züge weniger wahrscheinlich
gute Züge sind. Anstatt diese Züge komplett zu verwerfen, reduziert man
lediglich die Tiefe, bis zu der sie untersucht werden, und spart dadurch
Rechenzeit. Falls die verkürzte Suche jedoch einen Wert liefert, der über dem
aktuellen $\alpha$-Wert liegt, kann die Suche für diesen Zug erneut mit voller
Tiefe durchgeführt werden.

\section{Zugreihenfolge}

Die Effektivität des Spielbaum-Pruning hängt stark von der Reihenfolge ab, in
der die Zustände untersucht werden. Eine ungünstige Zugreihenfolge kann dazu
führen, dass Forward-Pruning-Verfahren auch gute Züge verwerfen und damit die
Genauigkeit der Suche beeinträchtigen. Beim Alpha-Beta-Verfahren führt eine
schlechte Zugordnung zwar nicht zu falschen Ergebnissen, kann die Suche jedoch
deutlich verlangsamen, da ungünstige Züge früh untersucht werden können und
dadurch weniger Möglichkeiten zum Abschneiden entstehen.

Könnte die Zugreihenfolge perfekt bestimmt werden, müsste Alpha-Beta-Pruning
zur Bestimmung des besten Zuges nur $O(b^{m/2})$ Knoten untersuchen, anstatt
$O(b^m)$ beim klassischen Minimax-Verfahren. Dies entspricht einem effektiven
Verzweigungsfaktor von $\sqrt{b}$ statt $b$ — im Schach also etwa $6$ statt
$35$. Anders ausgedrückt könnte Alpha-Beta-Pruning in diesem Fall bei gleicher
Rechenzeit einen Spielbaum etwa doppelt so tief durchsuchen wie der klassische
Minimax-Algorithmus.

Aus naheliegenden Gründen ist eine perfekte Zugordnung in den meisten Spielen
jedoch nicht erreichbar, da eine solche Ordnungsfunktion andernfalls direkt zur
Bestimmung einer optimalen Spielstrategie verwendet werden könnte. Trotzdem
kann man der idealen Ordnung relativ nahekommen.

Im Schach liefert bereits eine vergleichsweise einfache Zugordnungsheuristik,
die zunächst Schlagzüge, anschließend Drohungen, danach Vor- und zuletzt
Rückwärtszüge betrachtet, eine Annäherung an das Best-Case-Verhalten von
$O(b^{m/2})$.

Durch den Einsatz dynamischer Zugordnungsverfahren, etwa indem zuerst Züge
untersucht werden, die sich in früheren Suchen als besonders gut erwiesen
haben, lässt sich die Leistung weiter steigern.

\section{Horizon-Effekt}

In tiefenbegrenzten Spielbäumen endet die Suche in der Regel in Positionen, die
noch eine Reihe „offener“ Züge enthalten, wie wie Schläge oder Umwandlungen im
Schach, deren Ergebnis bei einer begrenzten Suchtiefe unvorhersehbar ist. Noch
schlimmer ist der Effekt von verzögerten Zügen, die unnötig den Zustand
schwächen, nur um die endgültige Niederlage hinauszuzögern, indem sie über die
maximale Suchtiefe hinausgeschoben wird. Dies wird als \textbf{Horizon-Effekt}
bezeichnet.

Eine 1-Ply-Suche aus dem Zustand, dargestellt in
Abbildung~\ref{fig:chess-position-illustrating-horizon-effect} würde den Zug
\texttt{Bxb3} finden, der nach Materialbewertung einen Bauern gewinnt. Aufgrund
der begrenzten Tiefe erkennt das Verfahren jedoch nicht, dass anschließend eine
Figur verloren geht, wodurch der anfängliche Materialvorteil wieder verloren
ist.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{Abbildungen/chess-position-illustrating-horizon-effect.png}
    \caption{Schachstellung zur Veranschaulichung des Horizon-Effekts (Schwarz am Zug)}
    \label{fig:chess-position-illustrating-horizon-effect}
\end{figure}

Daher sollte \textsc{eval} nur auf {\glqq}ruhige{\grqq} Positionen angewendet
werden, die keine {\glqq}offenen{\grqq} Züge mehr enthalten, die die Bewertung
stark verändern würden. Dazu ist eine zusätzliche \textbf{Quiescence Search}
erforderlich, um den Spielbaum so weit zu erweitern, bis eine solche Position
erreicht ist. Diese Suche wird normalerweise darauf beschränkt, nur bestimmte
Zugarten zu betrachten. Dies können die sämtlichen Antworten auf Schachzüge,
Schläge oder Teile einer einzigen komplexen Schlagfolge sein. Das Ziel besteht
stets darin, die Unsicherheiten in einem Zustand schnell aufzulösen, um eine
genauere Bewertung zu ermöglichen.

Leider kann der Läufer in dieser Stellung auf keine Weise gerettet werden.
Schwarz könnte jedoch auch eine Zugfolge in Betracht ziehen, die damit beginnt,
den König mit einem Bauern Schach zu bieten und den König dazu zu verleiten,
den Bauern zu schlagen. Dasselbe kann Schwarz anschließend mit einem zweiten
Bauern tun. Dadurch werden genügend Züge verbraucht, sodass der Verlust des
Läufers im weiteren Verlauf der Suche von Schwarz nicht erkannt wird. Schwarz
glaubt fälschlicherweise, dass der Läufer zu einem Preis von zwei Bauern
gerettet wurde, während in Wirklichkeit nur Bauern verschwendet und der
unvermeidliche Verlust des Läufers über die maximale Suchtiefe hinausgeschoben
wurde.

Eine Strategie zur Abschwächung dieses Problems sind \textbf{singuläre
Erweiterungen}. Die Idee besteht darin, einen Zug mit verlängerter Suchtiefe
erneut zu untersuchen, wenn dieser Zug deutlich besser zu sein scheint als alle
anderen Alternativen. In unserem Beispiel sind die Züge des Turms, die auf den
Läufer zielen, jeweils eindeutig bessere Züge. Selbst wenn also eine Folge von
Bauernzügen den Suchprozess an den Horizont drängt, erhalten diese klar
besseren Züge die Möglichkeit, die Suche zu verlängern. Wie genau
{\glqq}deutlich besser{\grqq} bestimmt wird, bleibt der jeweiligen
Implementierung überlassen.
